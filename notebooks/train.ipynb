{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\gvillanueva\\Desktop\\Technician_2022_2023\\Projects\\Mental_health_COVID19\\ds2024\\lib\\site-packages\\keras\\src\\losses.py:2940: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='openpyxl')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import linear_model\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from keras.layers import Dropout\n",
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), os.pardir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import utils\n",
    "from src.config import CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check/Create path\n",
    "for target in  CONFIG.outcomes:\n",
    "    if target != \"G_HADSscore\":\n",
    "        for n_features in CONFIG.n_features:\n",
    "            path_cv_data = CONFIG.path_results+\"/cv_data/\"+target+\"/\" +  str(n_features) + \"/\"\n",
    "            if os.path.exists(path_cv_data):\n",
    "                shutil.rmtree(path_cv_data)\n",
    "                os.makedirs(path_cv_data)\n",
    "            else:\n",
    "                os.makedirs(path_cv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loadind data ...\n",
      "Target discretization ...\n",
      "Number of features = 161\n",
      "--------------------------------------------------------\n",
      "Number of samples = 9291\n",
      "--------------------------------------------------------\n",
      "Number of categorical features = 114\n",
      "--------------------------------------------------------\n",
      "Number of numerical features = 47\n",
      "--------------------------------------------------------\n",
      "Number of features with missing values = 31\n",
      "Percentage of missing data =  0.34\n",
      "--------------------------------------------------------\n",
      "BATCH: 1 | CV: 1\n",
      "--------------------------------------------------------\n",
      "Imputing missing values ...\n",
      "One-hot-encoding ...\n",
      "Scaling data ...\n",
      "--------------------------------------------------------\n",
      "target = G_depressionscore\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "target = G_anxietyscore\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "target = G_totalscore\n",
      "--------------------------------------------------------\n",
      "BATCH: 1 | CV: 2\n",
      "--------------------------------------------------------\n",
      "Imputing missing values ...\n",
      "One-hot-encoding ...\n",
      "Scaling data ...\n",
      "--------------------------------------------------------\n",
      "target = G_depressionscore\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "target = G_anxietyscore\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "target = G_totalscore\n",
      "--------------------------------------------------------\n",
      "BATCH: 1 | CV: 3\n",
      "--------------------------------------------------------\n",
      "Imputing missing values ...\n",
      "One-hot-encoding ...\n",
      "Scaling data ...\n",
      "--------------------------------------------------------\n",
      "target = G_depressionscore\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "target = G_anxietyscore\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "target = G_totalscore\n",
      "--------------------------------------------------------\n",
      "BATCH: 1 | CV: 4\n",
      "--------------------------------------------------------\n",
      "Imputing missing values ...\n",
      "One-hot-encoding ...\n",
      "Scaling data ...\n",
      "--------------------------------------------------------\n",
      "target = G_depressionscore\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "target = G_anxietyscore\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "target = G_totalscore\n",
      "--------------------------------------------------------\n",
      "BATCH: 1 | CV: 5\n",
      "--------------------------------------------------------\n",
      "Imputing missing values ...\n",
      "One-hot-encoding ...\n",
      "Scaling data ...\n",
      "--------------------------------------------------------\n",
      "target = G_depressionscore\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "target = G_anxietyscore\n",
      "--------------------------------------------------------\n",
      "--------------------------------------------------------\n",
      "target = G_totalscore\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ########### Load data ############\n",
    "print('Loadind data ...')\n",
    "df_data, df_codebook  = utils.read_data(CONFIG.path_dataset, CONFIG.path_codebook)\n",
    "df_data = utils.data_preprocessing(df_data,df_codebook,CONFIG.non_relevant_vars, CONFIG.outcomes)\n",
    "\n",
    "############ Set target ############\n",
    "print('Target discretization ...')\n",
    "X,y_4 = utils.set_target(df_data,CONFIG.outcomes,CONFIG.thr_disc_1,CONFIG.thr_disc_2)\n",
    "y_3 = y_4.drop('G_HADSscore',axis=1)\n",
    "\n",
    "print('Number of features =',len(X.columns))\n",
    "print('--------------------------------------------------------')\n",
    "\n",
    "print('Number of samples =',X.shape[0])\n",
    "print('--------------------------------------------------------')\n",
    "\n",
    "############ Data encoding ############\n",
    "X, num_vars, categ_vars = utils.data_encoding(X,CONFIG.additional_categ_var)\n",
    "\n",
    "print('Number of categorical features =',len(categ_vars))\n",
    "print('--------------------------------------------------------')\n",
    "print('Number of numerical features =',len(num_vars))\n",
    "print('--------------------------------------------------------')\n",
    "\n",
    "missing_data=X.isna().sum()\n",
    "missing_data = missing_data[missing_data != 0]\n",
    "\n",
    "print('Number of features with missing values =', len(missing_data))\n",
    "print('Percentage of missing data = ', round(100*missing_data.sum()/(X.shape[0]*X.shape[1]),2))\n",
    "print('--------------------------------------------------------')\n",
    "\n",
    "cv_collection = []\n",
    "index_scores = []\n",
    "\n",
    "# Set outer cross-validation\n",
    "for i in range(CONFIG.outer_cv):\n",
    "    cv_t = StratifiedKFold(n_splits=CONFIG.inner_cv, shuffle=True)\n",
    "    cv_collection.append(cv_t)\n",
    "\n",
    "for count in range(len(cv_collection)):\n",
    "    for cv_i, (train_index, test_index) in enumerate(cv_collection[count].split(X, y_3[y_3.columns[0]])):\n",
    "\n",
    "        X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "        y_train_3, y_test_3 = y_3.iloc[train_index,:], y_3.iloc[test_index,:]\n",
    "\n",
    "        index_scores.append('BATCH: {} | CV: {} '.format(count + 1,cv_i+1))\n",
    "\n",
    "        print('BATCH: {} | CV: {}'.format(count + 1,cv_i+1))\n",
    "        print('--------------------------------------------------------')\n",
    "\n",
    "        ############ Imputation of missing values ############\n",
    "        print('Imputing missing values ...')\n",
    "        X_train, X_test = utils.data_imputation(X_train, X_test,categ_vars)\n",
    "\n",
    "        ############ One-hot-encoding ############\n",
    "        print('One-hot-encoding ...')\n",
    "        X_train, X_test = utils.data_one_hot_encoding(X_train, X_test, CONFIG.categ_nominal_var)\n",
    "\n",
    "        ############ Scale data ############\n",
    "        print('Scaling data ...')\n",
    "        X_train_scaled, X_test_scaled = utils.data_scale(X_train, X_test)\n",
    "\n",
    "        for target in y_3.columns:\n",
    "            \n",
    "            print('--------------------------------------------------------')\n",
    "            print('target =', target)\n",
    "            print('--------------------------------------------------------')\n",
    "\n",
    "            y_train = pd.DataFrame(y_train_3[target])\n",
    "            y_test = pd.DataFrame(y_test_3[target])\n",
    "\n",
    "            # Save full data\n",
    "            data_train_full = pd.concat([y_train,X_train], axis = 1)\n",
    "            data_test_full = pd.concat([y_test,X_test], axis = 1)\n",
    "\n",
    "            data_train_full_scaled = pd.concat([y_train,X_train_scaled], axis = 1)\n",
    "            data_test_full_scaled = pd.concat([y_test,X_test_scaled], axis = 1)\n",
    "\n",
    "            data = pd.concat([data_train_full,data_test_full],keys=['train','test'])\n",
    "            data.to_csv(CONFIG.path_results+\"/cv_data/\"+target+ \"/data_batch_\"+str(count+1)+\"_cv_\"+str(cv_i+1)+\".csv\")\n",
    "\n",
    "            data_scaled = pd.concat([data_train_full_scaled,data_test_full_scaled],keys=['train','test'])\n",
    "            data_scaled.to_csv(CONFIG.path_results+\"/cv_data/\"+target + \"/data_scaled_batch_\"+str(count+1)+\"_cv_\"+str(cv_i+1)+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Check/Create path\n",
    "for target in  CONFIG.outcomes:\n",
    "    if target != \"G_HADSscore\":\n",
    "        for n_features in CONFIG.n_features:\n",
    "            path_cv_data = CONFIG.path_results+\"/cv_data/\"+target+\"/\" +  str(n_features) + \"/\"\n",
    "            if os.path.exists(path_cv_data):\n",
    "                pass\n",
    "            else:\n",
    "                os.makedirs(path_cv_data)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Multi-Layer Perceptron\n"
     ]
    }
   ],
   "source": [
    "# ML model\n",
    "model_name = CONFIG.clf_name \n",
    "print(\"Model: \" + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check/Create path\n",
    "for out in  CONFIG.outcomes:\n",
    "    if out != 'G_HADSscore':\n",
    "        \n",
    "        if os.path.exists(CONFIG.path_results+\"results/\"+out+\"/\"+model_name+\"/\"):\n",
    "            shutil.rmtree(CONFIG.path_results+\"results/\"+out+\"/\"+model_name+\"/\")\n",
    "            os.makedirs(CONFIG.path_results+\"results/\"+out+\"/\"+model_name+\"/\")\n",
    "        else:\n",
    "            os.makedirs(CONFIG.path_results+\"results/\"+out+\"/\"+model_name+\"/\")\n",
    "\n",
    "        for n_features in  CONFIG.n_features:\n",
    "            if os.path.exists(CONFIG.path_results+\"models/\"+out+\"/\"+model_name+\"/\"+str(n_features)+\"/\"):\n",
    "                shutil.rmtree(CONFIG.path_results+\"models/\"+out+\"/\"+model_name+\"/\"+str(n_features)+\"/\")\n",
    "                os.makedirs(CONFIG.path_results+\"models/\"+out+\"/\"+model_name+\"/\"+str(n_features)+\"/\")\n",
    "            else:\n",
    "                os.makedirs(CONFIG.path_results+\"models/\"+out+\"/\"+model_name+\"/\"+str(n_features)+\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP model keras implementation\n",
    "def create_model(n_layers, learning_rate, l1, l2, act, dropout, n_features):                      \n",
    "    '''This is a model generating function so that we can search over neural net \n",
    "    parameters and architecture'''\n",
    "    \n",
    "    opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    reg = keras.regularizers.l1_l2(l1=l1, l2=l2)\n",
    "                                                    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # for the firt layer we need to specify the input dimensions\n",
    "    first=True\n",
    "\n",
    "    n_neurons = np.random.choice([25,50,100], size=n_layers)\n",
    "\n",
    "    for i in range(n_layers):\n",
    "        if first:\n",
    "            model.add(Dense(n_neurons[i], input_dim=n_features, activation=act, kernel_regularizer=reg))\n",
    "            first=False\n",
    "        else: \n",
    "            model.add(Dense(n_neurons[i], activation=act, kernel_regularizer=reg))\n",
    "        if dropout!=0:\n",
    "            model.add(Dropout(dropout))     \n",
    "\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************\n",
      "********************************************************\n",
      "                  target = G_depressionscore\n",
      "********************************************************\n",
      "********************************************************\n",
      "[batch, cv, n_features] = [1, 1, 25]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.768434198687133  --- one-standard-error:  0.002503557443501534\n",
      "Score test:  0.6856611563343759\n",
      "--------------------------------------------------------\n",
      "[batch, cv, n_features] = [1, 1, 100]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.7788044453755312  --- one-standard-error:  0.0034831453756534445\n",
      "Score test:  0.6860138476755687\n",
      "--------------------------------------------------------\n",
      "********************************************************\n",
      "********************************************************\n",
      "                  target = G_anxietyscore\n",
      "********************************************************\n",
      "********************************************************\n",
      "[batch, cv, n_features] = [1, 1, 25]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.7473673310091922  --- one-standard-error:  0.0035016220993249205\n",
      "Score test:  0.6595753605170936\n",
      "--------------------------------------------------------\n",
      "[batch, cv, n_features] = [1, 1, 100]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.7439075152113472  --- one-standard-error:  0.0031213112232687354\n",
      "Score test:  0.6574451081896805\n",
      "--------------------------------------------------------\n",
      "********************************************************\n",
      "********************************************************\n",
      "                  target = G_totalscore\n",
      "********************************************************\n",
      "********************************************************\n",
      "[batch, cv, n_features] = [1, 1, 25]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.7453993471042707  --- one-standard-error:  0.006135354606193321\n",
      "Score test:  0.6740724652565274\n",
      "--------------------------------------------------------\n",
      "[batch, cv, n_features] = [1, 1, 100]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.738368248586435  --- one-standard-error:  0.005060345260646414\n",
      "Score test:  0.6759978938268913\n",
      "--------------------------------------------------------\n",
      "********************************************************\n",
      "********************************************************\n",
      "                  target = G_depressionscore\n",
      "********************************************************\n",
      "********************************************************\n",
      "[batch, cv, n_features] = [1, 2, 25]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.7821302372920007  --- one-standard-error:  0.0064034226750903514\n",
      "Score test:  0.6626476935527381\n",
      "--------------------------------------------------------\n",
      "[batch, cv, n_features] = [1, 2, 100]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.7471238383624984  --- one-standard-error:  0.015270903866881208\n",
      "Score test:  0.6615721944968979\n",
      "--------------------------------------------------------\n",
      "********************************************************\n",
      "********************************************************\n",
      "                  target = G_anxietyscore\n",
      "********************************************************\n",
      "********************************************************\n",
      "[batch, cv, n_features] = [1, 2, 25]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.7348867888308604  --- one-standard-error:  0.006115171660020101\n",
      "Score test:  0.6324775378960888\n",
      "--------------------------------------------------------\n",
      "[batch, cv, n_features] = [1, 2, 100]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.7326587723837908  --- one-standard-error:  0.003294327489094529\n",
      "Score test:  0.6431105510774305\n",
      "--------------------------------------------------------\n",
      "********************************************************\n",
      "********************************************************\n",
      "                  target = G_totalscore\n",
      "********************************************************\n",
      "********************************************************\n",
      "[batch, cv, n_features] = [1, 2, 25]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.7493767035578781  --- one-standard-error:  0.0031250364048262683\n",
      "Score test:  0.6497941281775869\n",
      "--------------------------------------------------------\n",
      "[batch, cv, n_features] = [1, 2, 100]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.746807091507391  --- one-standard-error:  0.0021145598595766067\n",
      "Score test:  0.6505951299919918\n",
      "--------------------------------------------------------\n",
      "********************************************************\n",
      "********************************************************\n",
      "                  target = G_depressionscore\n",
      "********************************************************\n",
      "********************************************************\n",
      "[batch, cv, n_features] = [1, 3, 25]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.7708598488717098  --- one-standard-error:  0.005850631060365177\n",
      "Score test:  0.6742406592666045\n",
      "--------------------------------------------------------\n",
      "[batch, cv, n_features] = [1, 3, 100]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.7555195296385414  --- one-standard-error:  0.010313246407648247\n",
      "Score test:  0.6430761603111492\n",
      "--------------------------------------------------------\n",
      "********************************************************\n",
      "********************************************************\n",
      "                  target = G_anxietyscore\n",
      "********************************************************\n",
      "********************************************************\n",
      "[batch, cv, n_features] = [1, 3, 25]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.7410710309722834  --- one-standard-error:  0.005879516044068968\n",
      "Score test:  0.6625202415403422\n",
      "--------------------------------------------------------\n",
      "[batch, cv, n_features] = [1, 3, 100]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.7336904426517683  --- one-standard-error:  0.005575087453667162\n",
      "Score test:  0.6640639528202342\n",
      "--------------------------------------------------------\n",
      "********************************************************\n",
      "********************************************************\n",
      "                  target = G_totalscore\n",
      "********************************************************\n",
      "********************************************************\n",
      "[batch, cv, n_features] = [1, 3, 25]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.7533974065285187  --- one-standard-error:  0.006538940769931161\n",
      "Score test:  0.641466341556703\n",
      "--------------------------------------------------------\n",
      "[batch, cv, n_features] = [1, 3, 100]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.7378091288405871  --- one-standard-error:  0.0028656723818194204\n",
      "Score test:  0.6390464237903997\n",
      "--------------------------------------------------------\n",
      "********************************************************\n",
      "********************************************************\n",
      "                  target = G_depressionscore\n",
      "********************************************************\n",
      "********************************************************\n",
      "[batch, cv, n_features] = [1, 4, 25]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.769721880567203  --- one-standard-error:  0.007933148342376243\n",
      "Score test:  0.677451897749024\n",
      "--------------------------------------------------------\n",
      "[batch, cv, n_features] = [1, 4, 100]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.7802941187815219  --- one-standard-error:  0.007778082216897055\n",
      "Score test:  0.6827288442254084\n",
      "--------------------------------------------------------\n",
      "********************************************************\n",
      "********************************************************\n",
      "                  target = G_anxietyscore\n",
      "********************************************************\n",
      "********************************************************\n",
      "[batch, cv, n_features] = [1, 4, 25]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.7395980190689438  --- one-standard-error:  0.005378278680390389\n",
      "Score test:  0.6496815728176878\n",
      "--------------------------------------------------------\n",
      "[batch, cv, n_features] = [1, 4, 100]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.7469826275783068  --- one-standard-error:  0.004473264219651287\n",
      "Score test:  0.6427315203099997\n",
      "--------------------------------------------------------\n",
      "********************************************************\n",
      "********************************************************\n",
      "                  target = G_totalscore\n",
      "********************************************************\n",
      "********************************************************\n",
      "[batch, cv, n_features] = [1, 4, 25]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.7465106364295989  --- one-standard-error:  0.0037871411359351875\n",
      "Score test:  0.6501887180178013\n",
      "--------------------------------------------------------\n",
      "[batch, cv, n_features] = [1, 4, 100]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.6807830912340169  --- one-standard-error:  0.014463623319542191\n",
      "Score test:  0.6227050107112105\n",
      "--------------------------------------------------------\n",
      "********************************************************\n",
      "********************************************************\n",
      "                  target = G_depressionscore\n",
      "********************************************************\n",
      "********************************************************\n",
      "[batch, cv, n_features] = [1, 5, 25]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.7792004525281822  --- one-standard-error:  0.003597855821899448\n",
      "Score test:  0.6862266666948068\n",
      "--------------------------------------------------------\n",
      "[batch, cv, n_features] = [1, 5, 100]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.7839687835448658  --- one-standard-error:  0.0028249382897582924\n",
      "Score test:  0.705006900823315\n",
      "--------------------------------------------------------\n",
      "********************************************************\n",
      "********************************************************\n",
      "                  target = G_anxietyscore\n",
      "********************************************************\n",
      "********************************************************\n",
      "[batch, cv, n_features] = [1, 5, 25]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.7463667750406685  --- one-standard-error:  0.00946695754083476\n",
      "Score test:  0.6381417926683346\n",
      "--------------------------------------------------------\n",
      "[batch, cv, n_features] = [1, 5, 100]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.7467891841453326  --- one-standard-error:  0.008734835004598682\n",
      "Score test:  0.6535773903008607\n",
      "--------------------------------------------------------\n",
      "********************************************************\n",
      "********************************************************\n",
      "                  target = G_totalscore\n",
      "********************************************************\n",
      "********************************************************\n",
      "[batch, cv, n_features] = [1, 5, 25]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.753032276141649  --- one-standard-error:  0.006211967048043524\n",
      "Score test:  0.652173986201073\n",
      "--------------------------------------------------------\n",
      "[batch, cv, n_features] = [1, 5, 100]\n",
      "Selecting features...\n",
      "Optimizing model... \n",
      "mean score train:  0.7506919746767091  --- one-standard-error:  0.00477277764810287\n",
      "Score test:  0.6513461421747038\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for batch in range(CONFIG.outer_cv):\n",
    "    for cv in range(CONFIG.inner_cv):\n",
    "        \n",
    "        for target in CONFIG.outcomes:\n",
    "            \n",
    "            if target != 'G_HADSscore':\n",
    "                \n",
    "                print('********************************************************')\n",
    "                print('********************************************************')\n",
    "                print('                  target =', target)\n",
    "                print('********************************************************')\n",
    "                print('********************************************************')\n",
    "\n",
    "                path_data_scaled = CONFIG.path_results+\"/cv_data/\"+target + \"/data_scaled_batch_\"+str(batch+1)+\"_cv_\"+str(cv+1)+\".csv\"\n",
    "                data_scaled = pd.read_csv(path_data_scaled, index_col=[0,1])\n",
    "\n",
    "                data_train_scaled = data_scaled.loc['train']\n",
    "                y_train = data_train_scaled[target]\n",
    "                X_train_scaled = data_train_scaled.drop([target],axis=1)\n",
    "\n",
    "                data_test_scaled = data_scaled.loc['test']\n",
    "                y_test = data_test_scaled[target]\n",
    "                X_test_scaled = data_test_scaled.drop([target],axis=1)\n",
    "\n",
    "                path_data = CONFIG.path_results+\"/cv_data/\"+target + \"/data_batch_\"+str(batch+1)+\"_cv_\"+str(cv+1)+\".csv\"\n",
    "                data = pd.read_csv(path_data, index_col=[0,1])\n",
    "\n",
    "                data_train = data.loc['train']\n",
    "                y_train = data_train[target]\n",
    "                X_train = data_train.drop([target],axis=1)\n",
    "\n",
    "                data_test = data.loc['test']\n",
    "                y_test = data_test[target]\n",
    "                X_test = data_test.drop([target],axis=1)\n",
    "\n",
    "                # Set inner CV\n",
    "                cv_collection2 = []\n",
    "                cv_t2 = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "                cv_collection2.append(cv_t2)\n",
    "                cv_iter = []\n",
    "\n",
    "                for count2 in range(len(cv_collection2)):\n",
    "                    for cv_i2, (train_index, test_index) in enumerate(cv_collection2[count2].split(X_train_scaled, y_train)):\n",
    "                        cv_iter.append((train_index, test_index))\n",
    "                \n",
    "                test_scores = []\n",
    "                    \n",
    "                for n_features in CONFIG.n_features:\n",
    "                    print('[batch, cv, n_features] = [' + str(batch+1) + \", \" + str(cv+1) + \", \" + str(n_features) + \"]\")\n",
    "                    print('Selecting features...')\n",
    "                    X_train_red, X_train_scaled_red, X_test_red, X_test_scaled_red = utils.data_feature_selection(X_train, X_train_scaled, X_test, X_test_scaled, y_train, y_test, CONFIG.algorithm, n_features)\n",
    "\n",
    "                    # Save full data\n",
    "                    data_train_full = pd.concat([y_train,X_train_red], axis = 1)\n",
    "                    data_test_full = pd.concat([y_test,X_test_red], axis = 1)\n",
    "\n",
    "                    data_train_full_scaled = pd.concat([y_train,X_train_scaled_red], axis = 1)\n",
    "                    data_test_full_scaled = pd.concat([y_test,X_test_scaled_red], axis = 1)\n",
    "\n",
    "                    data = pd.concat([data_train_full,data_test_full],keys=['train','test'])\n",
    "                    data.to_csv(CONFIG.path_results+\"/cv_data/\"+target+\"/\" + str(n_features) + \"/data_batch_\"+str(batch+1)+\"_cv_\"+str(cv+1)+\".csv\")\n",
    "\n",
    "                    data_scaled = pd.concat([data_train_full_scaled,data_test_full_scaled],keys=['train','test'])\n",
    "                    data_scaled.to_csv(CONFIG.path_results+\"/cv_data/\"+target+\"/\" + str(n_features) + \"/data_scaled_batch_\"+str(batch+1)+\"_cv_\"+str(cv+1)+\".csv\")\n",
    "\n",
    "                    ############ Optimize model ############\n",
    "                    print('Optimizing model... ')\n",
    "\n",
    "                    # Choose model\n",
    "                    if CONFIG.clf_name == \"XGBoost\":\n",
    "                        clf = XGBClassifier(objective='multi:softprob',num_class=3,n_estimators = 50, learning_rate = 0.25, booster = 'gbtree', max_depth = 3)\n",
    "                    elif CONFIG.clf_name == \"Multi-Layer Perceptron\":        \n",
    "                        clf  = KerasClassifier(build_fn=create_model, n_features = 25, epochs=25, batch_size=20, verbose=0, n_layers=1 , learning_rate=0.01, l1=0.01, l2=0.01, act = 'relu', dropout=0)\n",
    "                    elif CONFIG.clf_name == \"Random Forest\":\n",
    "                        clf = RandomForestClassifier(n_estimators = 100)\n",
    "                    elif CONFIG.clf_name == \"Support Vector Machines\":\n",
    "                        clf = SVC(kernel=\"rbf\", probability=True, max_iter = 5000)\n",
    "                    elif CONFIG.clf_name == \"Naive Bayes\":\n",
    "                        clf = GaussianNB()\n",
    "                    elif CONFIG.clf_name == \"Logistic Regression\":\n",
    "                        clf = linear_model.LogisticRegression(multi_class='ovr', solver='liblinear')\n",
    "                    \n",
    "                    best_model, best_params, best_score = utils.grid_search(X_train_red, X_train_scaled_red, y_train, clf, CONFIG.clf_name, target,CONFIG.n_iter,cv_iter,CONFIG.n_features)\n",
    "\n",
    "                    # Save model\n",
    "                    if CONFIG.clf_name == \"Multi-Layer Perceptron\":\n",
    "                        best_model.model_.save(CONFIG.path_results+\"models/\"+target+\"/\"+model_name+\"/\"+str(n_features)+ \"/model_batch_\"+str(batch+1)+\"_cv_\"+str(cv+1)+\".keras\")\n",
    "                    else:\n",
    "                        joblib.dump(best_model, CONFIG.path_results+\"models/\"+target+\"/\"+model_name+\"/\"+str(n_features)+ \"/model_batch_\"+str(batch+1)+\"_cv_\"+str(cv+1)+\".sav\")\n",
    "      \n",
    "                    scores = []\n",
    "                    au = np.where(best_score['rank_test_score']==1)[0]\n",
    "                    for i in range(CONFIG.inner_cv):\n",
    "                        split_name = 'split'+ str(i) + '_test_score'\n",
    "                        au2 = best_score[split_name]\n",
    "                        scores.append(np.abs(au2[au])[0])\n",
    "\n",
    "                    test_scores.append(scores)\n",
    "                    cv_se = np.std(scores)/np.sqrt(5) \n",
    "\n",
    "                    print(\"mean score train: \", np.mean(scores),\" --- one-standard-error: \",cv_se)\n",
    "\n",
    "                    if CONFIG.clf_name == \"Multi-Layer Perceptron\":\n",
    "                        y_prob = best_model.predict(X_test_scaled_red)\n",
    "                        y_pred = np.argmax(y_prob,axis=1)\n",
    "                    else:\n",
    "                        y_pred = best_model.predict(X_test_scaled_red)\n",
    "                        y_prob = best_model.predict_proba(X_test_scaled_red)\n",
    "\n",
    "                    # Print metrics\n",
    "                    value2 = roc_auc_score(y_test, y_prob,multi_class=\"ovo\",average = \"macro\")\n",
    "                    #value2 = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "                    \n",
    "                    print(\"Score test: \", value2)\n",
    "                    print('--------------------------------------------------------')\n",
    "            \n",
    "                # save inner-cv scores\n",
    "                column_names = ['1','2','3','4','5']\n",
    "                performance_report = pd.DataFrame(test_scores, columns= column_names, index=CONFIG.n_features)\n",
    "                performance_report.to_csv(CONFIG.path_results +\"results/\"+target + \"/\" + model_name + \"/scores\"+str(batch+1)+\"_cv_\"+str(cv+1)+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
